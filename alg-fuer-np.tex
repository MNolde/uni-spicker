\documentclass{cheat-sheet}

\pdfinfo{
  /Title (Zusammenfassung Algorithmen für NP-harte Probleme)
  /Author (Tim Baumann)
}

%\usepackage{algorithmicx}
%\usepackage[noend]{algpseudocode}
%\usepackage{tikz}
%\tikzset{
%  font={\fontsize{6pt}{12}\selectfont}
%}

\usepackage{nicefrac}

\newcommand{\Instances}{\mathcal{X}} % set of instances (of an optimization problem)
\newcommand{\Feasible}{\mathcal{F}} % set of feasible solutions (of an optimization problem)
\newcommand{\ObjFun}{Z} % objective function (of an optimization problem)
\newcommand{\OptTuple}{(\Instances{}, \Feasible{}, \ObjFun{})} % tuple defining an optimization problem
\DeclareMathOperator{\Opt}{Opt} % optimal value
\newcommand{\size}[1]{\abs{#1}} % Größe (eines Terms)
\DeclareMathOperator{\NPO}{NPO} % non-deterministic polynomial-time optimization problem
\DeclareMathOperator{\PO}{PO} % polynomial-time optimization problem
\newcommand{\Prob}{\mathcal{P}} % Optimierungsproblem
\newcommand{\ManyOneRed}{\leq_m} % Many-To-One-Reduzierbarkeit
\newcommand{\TuringRed}{\leq_T} % Turing-Reduzierbarkeit
\newcommand{\TuringEq}{\equiv_T} % Turing-Äquivalenz
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\Powerset}{\mathcal{P}} % Potenzmenge

% Hervorhebung von Algorithmen und Problemen
\definecolor{AlgorithmColor}{rgb}{0.7,0.2,0.0}
\newcommand{\Algorithm}[1]{\textcolor{AlgorithmColor}{\textbf{#1}}}
\definecolor{ProblemColor}{rgb}{0.1,0.5,0.4}
\newcommand{\Problem}[1]{\textcolor{ProblemColor}{\textbf{#1}}}

% Kleinere Klammern
\delimiterfactor=701

\setlength{\tabcolsep}{2pt}

\begin{document}

\raggedcolumns % stretche Inhalt nicht über die gesamte Spaltenhöhe

\maketitle{Algorithmen für NP-harte Probleme}

Dies ist eine Zusammenfassung zur gleichnamigen Vorlesung von Professor Dr. Torben Hagerup im Sommersemester 2017.

% §1. Introduction

% §2. Basic Definitions

% §2.1. Basic Definitions

% 2.1
\begin{defn}
  Ein \emph{Optimierungsproblem} ist ein Tupel $\OptTuple$ wobei
  \begin{itemize}
    \item $\Instances$ eine Menge von \emph{Instanzen},
    \item $\Feasible$ eine Abbildung ist, welche jeder Instanz~$x$ eine Menge $\Feasible(x)$ von \emph{möglichen Lösungen} zuordnet und
    \item $\ObjFun$ eine reellwertige Abbildung (die \emph{Zielfunktion}) ist, die jedem $x \in \Instances$ und $y \in \Feasible(x)$ einen \textit{Zielwert} zuordnet.
  \end{itemize}
\end{defn}

% 2.2
\begin{defn}
  Eine \emph{optimale Lösung} eines Optimierungsproblems~$\OptTuple$ zu einer Instanz~$x \in \Instances$ ist ein $y \in \Feasible(x)$ mit
  \[ \ObjFun(x, y) = \min_{y \in \Feasible(x)} Z(x, y) =: \Opt(x). \]
\end{defn}

% 2.3
\begin{defn}
  Ein Algorithmus \emph{löst} ein Optimierungsproblem~$\OptTuple$, falls er für jedes $x \in \Instances$
  \begin{itemize}
    \item eine optimale Lösung $y \in \Feasible(x)$ berechnet, falls solch eine existiert,
    \item "`unmöglich"' ausgibt, falls keine Lösung existiert oder
    \item "`möglich, aber keine optimale Lösung"' sonst.
  \end{itemize}
\end{defn}

% 2.4
\begin{defn}
  \emph{$\NPO$} ist die Klasse aller Optimierungsprobleme~$\OptTuple$ mit
  \begin{itemize}
    \item $\Instances{} \in P$
    \item Es gibt ein Polynom~$p$, sodass für alle $x \in X$
    \begin{itemize}
      \item $\size{y} \leq p(\size{x})$ für alle $y \in \Feasible(x)$ und
      \item für alle Wörter~$w$ der Länge $\size{w} \leq p(\size{x})$ in polynomieller Zeit~(in~$\size{x}$) entscheidbar ist, ob $w \in \Feasible(x)$.
    \end{itemize}
    \item Die Funktion $\ObjFun$ ist in polynomieller Zeit berechenbar.
  \end{itemize}
\end{defn}

% 2.5
\begin{defn}
  $\text{\emph{$\PO$}} \subseteq \NPO$ ist die Subklasse für die ein Lösungsalgorithmus existiert, der in Polynomialzeit läuft.
\end{defn}

% 2.6
\begin{beob}
  $\PO = \NPO \implies \text{P} = \text{NP}$
\end{beob}

% §2.2. Evaluation and Decision Problems

% 2.7
\begin{defn}
  Sei $\Prob = \OptTuple$ ein Optimierungsproblem.
  \begin{itemize}
    \item Das zugeh. \emph{Auswertungsproblem}~$\Prob_E$ ist: Gegeben $x \in \Instances$,
    \begin{itemize}
      \item berechne $\Opt(x)$, falls $x$ eine optimale Lösung besitzt,
      \item berechne $\inf \Feasible(x) \in \R \cup \{ -\infty \}$, falls es Lösungen gibt, aber keine optimale
      \item oder gib "`unmöglich"' aus, falls keine Lösung existiert.
    \end{itemize}
    \item Das zugeh. \emph{Entscheidungsproblem}~$\Prob_D$ ist: Gegeben $x \in \Instances$ und $k \in \Q$, gibt es eine Lösung $y \in \Feasible(x)$ mit $Z(x, y) \leq k$?
  \end{itemize}
\end{defn}

% 2.8
\begin{defn}
  $\Prob \in \NPO \implies \Prob_D \in \mathrm{NP}$
\end{defn}

% 2.9
\begin{defn}
  \begin{itemize}
    \item Ein Entscheidungsproblem~$\Prob_1$ ist (in Polynomialzeit) auf ein Entscheidungsproblem~$\Prob_2$ \emph{many-to-one-reduzierbar} (notiert $\Prob_1 \ManyOneRed \Prob_2$) falls eine (in Polynomialzeit) berechenbare Funktion $f : \{ \text{Instanzen von~$\Prob_1$} \} \to \{ \text{Instanzen von~$\Prob_2$} \}$ existiert, sodass die Antwort auf eine Instanz~$x$ von~$\Prob_1$ gleich der Antwort auf die Instanz $f(x)$ von~$\Prob_2$ ist.
    \item Ein Problem $\Prob_1$ ist (in Polynomialzeit) auf ein Problem~$\Prob_2$ \emph{Turing-reduzierbar} (notiert $\Prob_1 \TuringRed \Prob_2$) falls ein Algorithmus existiert, der unter Verwendung eines Orakels für~$\Prob_2$ das Problem~$\Prob_1$ (in Polynomialzeit) löst.
  \end{itemize}
\end{defn}

% 2.12
\begin{beob}
  $
    \Prob_1 \ManyOneRed \Prob_2 \implies
    \Prob_1 \TuringRed \Prob_2
  $
\end{beob}

% 2.10
\begin{beob}
  Für $\Prob \in \NPO$ gilt $\Prob_D \TuringRed \Prob_E \TuringRed \Prob$.
\end{beob}

% 2.11 und 2.13
\begin{satz}
  Habe $\Prob = \OptTuple \in \NPO$ eine Zielfunktion mit Werten in den ganzen Zahlen.
  \begin{itemize}
    \item Es gilt $\Prob_D \TuringEq \Prob_E$.
    \item Angenommen, $\Prob_D$ ist NP-vollständig. Dann gilt $\Prob \TuringEq \Prob_D$.
  \end{itemize}
\end{satz}

% 2.14
\begin{defn}
  Ein Optimierungsproblem~$\Prob$ heißt \emph{NP-hart}, falls $\Prob' \TuringRed \Prob$ für jedes Entscheidungsproblem $\Prob'$ in~NP.
\end{defn}

% 2.15
\begin{beob}
  $\Prob \in \NPO$, $\Prob$ NP-vollständig $\implies$ $\Prob$ NP-hart
\end{beob}

% §3. The Greedy Strategy
\section{Die Gierige Strategie}

% §3.1 A cabin manager's problem

\begin{problem}[Cabin Manager's Problem]
  MIS auf Intervallgraphen
\end{problem}

% §3.2 Maximum Independent Set for Interval Models

\begin{alg}[\Algorithm{Greedy MIS für Intervallgraphen}] \mbox{}\\
  Beginne mit $C \coloneqq \emptyset$, füge dann wiederholt gierig das vom aktuellen~$C$ unabhängige Intervall mit dem kleinsten Endpunkt zu~$C$ hinzu, bis es kein solches Intervall mehr gibt.
\end{alg}

\begin{satz}
  Dieser Algorithmus berechnet tatsächlich ein MIS.
\end{satz}

% §3.3. Minimum Makespan Scheduling

\begin{alg}[\Algorithm{Greedy Minimum Makespan Scheduling}] \mbox{}\\
  Gehe die Jobs in nach Dauer absteigender Reihenfolge durch, weise jeden Job dem Arbeiter zu, der bisher am wenigsten ausgelastet ist.
\end{alg}

\begin{satz}
  Die Lösung, die der Alg. liefert, ist höchstens um den Faktor
  \[ \nicefrac{4}{3} - \nicefrac{1}{3 p} \]
  schlechter als eine optimale Lösung.
\end{satz}

\begin{beweisskizze}
  Sei $t$ die Länge des letzten Jobs des am längsten beschäftigten Arbeiters und $z^*$ die minimale Gesamtdauer.
  \begin{itemize}
    \item Falls $t > \nicefrac{z^*}{3}$, so hat der Alg. sogar eine optimale Lsg gefunden.
    \item Falls $t \leq \nicefrac{z^*}{3}$, so folgt die Behauptung durch geeign. Abschätzen.
  \end{itemize}
\end{beweisskizze}

% §3.4. Maximum Knapsack

\begin{alg}[\Algorithm{Greedy Knapsack Packing}]
  Gehe die Sachen absteigend nach ihrem Nutzen-Kosten-Verhältnis~$\nicefrac{v_i}{w_i}$ durch und packe jede Sache ein, die noch in den Rucksack passt.
  Sei~$z$ der Gesamtnutzen des so zusammengestellten Sets.
  Falls eine Sache mit Nutzen $v_j > z$ (und $w_j \leq W$) nicht eingepackt wurde, so räume den Rucksack wieder aus und packe als einziges diese Sache ein.
\end{alg}

\begin{satz}
  Der Gesamtnutzen der durch den Algorithmus erhaltenen Lösung ist mindestens halb so groß wie der Gesamtnutzen einer optimalen Lösung.
\end{satz}

% §3.5. Minimum Set Cover

\begin{alg}[\Algorithm{Greedy Minimum Set Cover}]
  Beginne mit $\mathcal{C} \coloneqq \emptyset$, füge dann immer ein $T \in \mathcal{C}_0$ zu~$\mathcal{C}$ hinzu, welches
  \[ T \cap \left( {\bigcup}_{S \in \mathcal{C}_0} S \setminus {\bigcup}_{S \in \mathcal{C}} S \right) \]
  maximiert, bis ${\bigcup}_{S \in \mathcal{C}_0} S = {\bigcup}_{S \in \mathcal{C}} S$.
\end{alg}

% 3.5
\begin{satz}
  Sei $n \coloneqq {\max}_{S \in \mathcal{C}_0} \size{S}$.
  Die vom Greedy-Algorithmus berechnete Lösung ist maximal um den Faktor $H_n \coloneqq {\sum}_{j=1}^n \nicefrac{1}{j}$ schlechter als die optimale Lösung.
\end{satz}

% §3.6. Minimum Vertex Coloring

\begin{bem}
  Es gibt keinen (einfachen) Greedy-Algorithmus, der das Minimum-Vertex-Coloring-Problem in guten Schranken löst.
\end{bem}

\section{Probleme}

\begin{problem}[\Problem{Maximum Independent Set}, MIS]
  Geg. einen unger. Graphen~$(V, E)$, berechne eine \textit{unabh. Menge}~$M \subseteq V$, \dh{}
  \[
    \fa{v \in M} \fa{w \in V} (v, w) \in E \implies w \not\in M,
  \]
  die maximale Größe~$\size{M}$ unter allen unabhängigen Mengen besitzt.
\end{problem}

\begin{problem}[\Problem{Minimum Vertex Cover}, MVC]
  Geg. einen unger. Graphen~$G = (V, E)$, berechne eine \textit{Knotenüberdeckung}~$C$, \dh{}
  \[
    \fa{v, w \in V} (v, w) \in E \implies v \in C \vee w \in C,
  \]
  die minimale Größe~$\size{C}$ unter allen Knotenüberdeckungen besitzt.
\end{problem}

\begin{bem}
  Für einen Graphen $(V, E)$ und eine Teilmenge $S \subseteq V$ gilt: \\
  $S$ ist eine unabhängige Menge $\iff$ $V \setminus S$ ist ein Vertex Cover \\
  Die Probleme MIS und MVC sind damit äquivalent.
\end{bem}

\begin{defn}
  Ein \emph{Intervallmodell} eines Graphen $G = (V, E)$ ist eine Abbildung $\phi : E \to \Set{\cinterval{a}{b}}{a, b \in \Q}$, sodass
  \[
    \fa{v \neq w \in V} \enspace
    (v, w) \in E \iff \phi(v) \cap \phi(w) \neq \emptyset.
  \]
  Ein Graph heißt \emph{Intervallgraph}, falls er ein Intervallmodell besitzt.
\end{defn}

\begin{problem}[\Problem{Minimum Makespan Scheduling}]
  Seien $p, n \in \N$ und $l_1, \ldots, l_n \in \R_{> 0}$ gegeben.
  Für $f : \{ 1, \ldots, n \} \to \{ 1, \ldots, p \}$ setze
  \[ t(f) \coloneqq \max_{1 \leq i \leq p} \sum_{j \in f^{-1}(i) l_j}. \]
  Berechne das~$f$, für das $t(f)$ minimal wird!
\end{problem}

\begin{interp}
  $p$ ist die Anzahl von \textit{Arbeitern},
  $l_1, \ldots, l_n$ sind die Längen von zu erledigenden \textit{Jobs}
  und $t(f)$ ist die \textit{Gesamtdauer} bei der durch~$f$ gegebenen Verteilung der Jobs auf die Arbeiter an.
\end{interp}

\begin{bem}
  MMS ist NP-hart, da das zugeh. Entscheidungsproblem Bin Packing bekannterweise NP-hart ist.
\end{bem}

\begin{problem}[\Problem{Maximum Knapsack}]
  Seien $n \in \N$ und $v_1, \ldots, v_n$, $w_1, \ldots, w_n, W \in \R_{> 0}$ gegeben.
  Die Menge der möglichen Lsgn sei
  \[ \Feasible \coloneqq \Set{S \subseteq \{ 1, \ldots, n \}}{{\sum}_{i \in S} w_i \leq W}. \]
  Gesucht: ${\argmax}_{S \in \Feasible} {\sum}_{i \in S} v_i$
\end{problem}

\begin{interp}
  Man wählt unter $n$ Sachen mit jeweils einem \textit{Gewicht}~$w_i$ und einem \textit{Nutzwert}~$v_i$ diejenigen aus, die man in einen Rucksack packt, sodass das Gesamtgewicht eine festgelegte Grenze~$W$ nicht übersteigt und der Nutzen maximal wird.
\end{interp}

\begin{problem}[\Problem{Minimum Set Cover}]
  Gegeben seien $n \in \N$ und $\mathcal{C}_0 \subseteq \Powerset(\{ 1, \ldots, n \})$.
  Die Menge der möglichen Lösungen ist
  \[ \Feasible \coloneqq \Set{\mathcal{C} \subseteq \mathcal{C}_0}{{\bigcup}_{S \in \mathcal{C}} S = {\bigcup}_{S \in \mathcal{C}_0} S} \]
  Aufgabe: Finde $\mathcal{C} \in \Feasible$ mit minimalem $\size{\mathcal{C}}$!
\end{problem}

\begin{bem}
  Minimum Set Cover verallgemeinert Minimum Vertex Cover.
\end{bem}

\begin{problem}[\Problem{Minimum Vertex Coloring}]
  Gegeben sei ein ungerichteter Graph~$G = (V, E)$.
  Die Menge der \textit{Färbungen} ist
  \[
    \Feasible \coloneqq \Set{\text{Abbildungen } c : V \to \N}{\fa{(v, w) \in E} c(v) \neq c(w)}.
  \]
  Ziel: Finde $c \in \Feasible$ mit minimaler Anzahl $\max c(V)$ an Farben.
\end{problem}

\end{document}
