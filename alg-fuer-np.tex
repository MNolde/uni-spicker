\documentclass{cheat-sheet}

\pdfinfo{
  /Title (Zusammenfassung Algorithmen für NP-harte Probleme)
  /Author (Tim Baumann)
}

%\usepackage{algorithmicx}
%\usepackage[noend]{algpseudocode}
%\usepackage{tikz}
%\tikzset{
%  font={\fontsize{6pt}{12}\selectfont}
%}

\usepackage{nicefrac}

\newcommand{\Instances}{\mathcal{X}} % set of instances (of an optimization problem)
\newcommand{\Feasible}{\mathcal{F}} % set of feasible solutions (of an optimization problem)
\newcommand{\ObjFun}{Z} % objective function (of an optimization problem)
\newcommand{\Goal}{\odot} % whether to minimize or maximize
\newcommand{\OptTuple}{(\Instances{}, \Feasible{}, \ObjFun{}, \Goal)} % tuple defining an optimization problem
\newcommand{\MinOptTuple}{(\Instances{}, \Feasible{}, \ObjFun{}, \min)} % tuple defining an optimization problem where the goal is to minimize the objective function
\DeclareMathOperator{\Opt}{Opt} % optimal value
\newcommand{\size}[1]{\abs{#1}} % Größe (eines Terms)
\DeclareMathOperator{\NPO}{NPO} % non-deterministic polynomial-time optimization problem
\DeclareMathOperator{\PO}{PO} % polynomial-time optimization problem
\DeclareMathOperator{\APX}{APX} % polynomial-time approximable optimization problem
\DeclareMathOperator{\NP}{NP} % nondeterministic polynomial-time problems
\let\P\relax % undefine \P
\DeclareMathOperator{\P}{P} % polynomial-time problems
\DeclareMathOperator{\PTAS}{PTAS} % polynomial-time approximation schema, class of problems in NPO that possess such
\DeclareMathOperator{\APTAS}{APTAS} % asymptotic polynomial-time approximation schema, class of problems in NPO that possess such
\DeclareMathOperator{\FPTAS}{FPTAS} % fully polynomial-time approximation schema, class of problems in NPO that possess such
\DeclareMathOperator{\AFPTAS}{AFPTAS} % asymptotic fully polynomial-time approximation schema, class of problems in NPO that possess such
\newcommand{\Prob}{\mathcal{P}} % Optimierungsproblem
\newcommand{\ManyOneRed}{\leq_m} % Many-To-One-Reduzierbarkeit
\newcommand{\TuringRed}{\leq_T} % Turing-Reduzierbarkeit
\newcommand{\TuringEq}{\equiv_T} % Turing-Äquivalenz
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\Powerset}{\mathcal{P}} % Potenzmenge
\renewcommand{\O}{\mathcal{O}} % Landau-Notation
\newcommand{\floor}[1]{\lfloor #1 \rfloor} % Abrunden

% Hervorhebung von Algorithmen und Problemen
\definecolor{AlgorithmColor}{rgb}{0.7,0.2,0.0}
\newcommand{\Algorithm}[1]{\textcolor{AlgorithmColor}{\textbf{#1}}}
\definecolor{ProblemColor}{rgb}{0.1,0.5,0.4}
\newcommand{\Problem}[1]{\textcolor{ProblemColor}{\textbf{#1}}}
\definecolor{DefinitionColor}{rgb}{1,0.255,0.212}
\newcommand{\Defn}[1]{\textcolor{DefinitionColor}{#1}}

\usepackage{algorithmicx}
\usepackage[noend]{algpseudocode}

% Kleinere Klammern
\delimiterfactor=701

\setlength{\tabcolsep}{2pt}

\begin{document}

\raggedcolumns % stretche Inhalt nicht über die gesamte Spaltenhöhe

\maketitle{Algorithmen für NP-harte Probleme}

Dies ist eine Zusammenfassung zur gleichnamigen Vorlesung von Professor Dr. Torben Hagerup im Sommersemester 2017.

% §1. Introduction

% §2. Basic Definitions

% §2.1. Basic Definitions

% 2.1
\begin{defn}
  Ein \emph{Optimierungsproblem} ist ein Tupel $\OptTuple$ wobei
  \begin{itemize}
    \item $\Instances$ eine Menge von \emph{Instanzen},
    \item $\Feasible$ eine Abbildung ist, welche jeder Instanz~$x$ eine Menge $\Feasible(x)$ von \emph{möglichen Lösungen} zuordnet,
    \item $\ObjFun$ eine reellwertige Abbildung (die \emph{Zielfunktion}) ist, die jedem $x \in \Instances$ und $y \in \Feasible(x)$ einen \textit{Zielwert} zuordnet und
    \item $\Goal \in \{ \min, \max \}$ angibt, ob die Zielfunktion minimiert oder maximiert werden soll.
  \end{itemize}
\end{defn}

% 2.2
\begin{defn}
  Eine \emph{optimale Lösung} eines Optimierungsproblems $\OptTuple$ zu einer Instanz~$x \in \Instances$ ist ein $y \in \Feasible(x)$ mit
  \[ \ObjFun(x, y) = \Goal_{y \in \Feasible(x)} Z(x, y) =: \Opt(x). \]
\end{defn}

% 2.3
\begin{defn}
  Ein Algorithmus \emph{löst} ein Optimierungsproblem~$\OptTuple$, falls er für jedes $x \in \Instances$
  \begin{itemize}
    \item eine optimale Lösung $y \in \Feasible(x)$ berechnet, falls solch eine existiert,
    \item "`unmöglich"' ausgibt, falls keine Lösung existiert oder
    \item "`möglich, aber keine optimale Lösung"' sonst.
  \end{itemize}
\end{defn}

% 2.4
\begin{defn}
  \Defn{$\NPO$} ist die Klasse aller Opt.-Probleme~$\OptTuple$ mit
  \begin{itemize}
    \item $\Instances{} \in P$
    \item Es gibt ein Polynom~$p$, sodass für alle $x \in X$
    \begin{itemize}
      \item $\size{y} \leq p(\size{x})$ für alle $y \in \Feasible(x)$ und
      \item für alle Wörter~$w$ der Länge $\size{w} \leq p(\size{x})$ in polynomieller Zeit~(in~$\size{x}$) entscheidbar ist, ob $w \in \Feasible(x)$.
    \end{itemize}
    \item Die Funktion $\ObjFun$ ist in polynomieller Zeit berechenbar.
  \end{itemize}
\end{defn}

% 2.5
\begin{defn}
  $\Defn{\PO} \subseteq \NPO$ ist die Subklasse für die ein Lösungsalgorithmus existiert, der in Polynomialzeit läuft.
\end{defn}

% 2.6
\begin{beob}
  $\PO = \NPO \implies \text{P} = \text{NP}$
\end{beob}

% §2.2. Evaluation and Decision Problems

% 2.7
\begin{defn}
  Sei $\Prob = \MinOptTuple$ ein Optimierungsproblem.
  \begin{itemize}
    \item Das zugeh. \emph{Auswertungsproblem}~$\Prob_E$ ist: Gegeben $x \in \Instances$,
    \begin{itemize}
      \item berechne $\Opt(x)$, falls $x$ eine optimale Lösung besitzt,
      \item berechne $\inf \Feasible(x) \in \R \cup \{ -\infty \}$, falls es Lösungen gibt, aber keine optimale
      \item oder gib "`unmöglich"' aus, falls keine Lösung existiert.
    \end{itemize}
    \item Das zugeh. \emph{Entscheidungsproblem}~$\Prob_D$ ist: Gegeben $x \in \Instances$ und $k \in \Q$, gibt es eine Lösung $y \in \Feasible(x)$ mit $Z(x, y) \leq k$?
  \end{itemize}
\end{defn}

% 2.8
\begin{lem}
  $\Prob \in \NPO \implies \Prob_D \in \mathrm{NP}$
\end{lem}

% 2.9
\begin{defn}
  \begin{itemize}
    \item Ein Entscheidungsproblem~$\Prob_1$ ist (in Polynomialzeit) auf ein Entscheidungsproblem~$\Prob_2$ \emph{many-to-one-reduzierbar} (notiert $\Prob_1 \ManyOneRed \Prob_2$) falls eine (in Polynomialzeit) berechenbare Funktion $f : \{ \text{Instanzen von~$\Prob_1$} \} \to \{ \text{Instanzen von~$\Prob_2$} \}$ existiert, sodass die Antwort auf eine Instanz~$x$ von~$\Prob_1$ gleich der Antwort auf die Instanz $f(x)$ von~$\Prob_2$ ist.
    \item Ein Problem $\Prob_1$ ist (in Polynomialzeit) auf ein Problem~$\Prob_2$ \emph{Turing-reduzierbar} (notiert $\Prob_1 \TuringRed \Prob_2$) falls ein Algorithmus existiert, der unter Verwendung eines Orakels für~$\Prob_2$ das Problem~$\Prob_1$ (in Polynomialzeit) löst.
  \end{itemize}
\end{defn}

% 2.12
\begin{beob}
  $
    \Prob_1 \ManyOneRed \Prob_2 \implies
    \Prob_1 \TuringRed \Prob_2
  $
\end{beob}

% 2.10
\begin{beob}
  Für $\Prob \in \NPO$ gilt $\Prob_D \TuringRed \Prob_E \TuringRed \Prob$.
\end{beob}

% 2.11 und 2.13
\begin{satz}
  Habe $\Prob = \OptTuple \in \NPO$ eine Zielfunktion mit Werten in den ganzen Zahlen.
  \begin{itemize}
    \item Es gilt $\Prob_D \TuringEq \Prob_E$.
    \item Angenommen, $\Prob_D$ ist NP-vollständig. Dann gilt $\Prob \TuringEq \Prob_D$.
  \end{itemize}
\end{satz}

% 2.14
\begin{defn}
  Ein Optimierungsproblem~$\Prob$ heißt \emph{NP-hart}, falls $\Prob' \TuringRed \Prob$ für jedes Entscheidungsproblem $\Prob'$ in~NP.
\end{defn}

\begin{samepage}

% 2.15
\begin{beob}
  $\Prob \in \NPO$, $\Prob$ NP-vollständig $\implies$ $\Prob$ NP-hart
\end{beob}

% §3. The Greedy Strategy
\section{Die Gierige Strategie}

% §3.1 A cabin manager's problem

\begin{problem}[Cabin Manager's Problem]
  MIS auf Intervallgraphen
\end{problem}

\end{samepage}

% §3.2 Maximum Independent Set for Interval Models

\begin{alg}[\Algorithm{Greedy MIS für Intervallgraphen}] \mbox{}\\
  Beginne mit $C \coloneqq \emptyset$, füge dann wiederholt gierig das vom aktuellen~$C$ unabhängige Intervall mit dem kleinsten Endpunkt zu~$C$ hinzu, bis es kein solches Intervall mehr gibt.
\end{alg}

\begin{satz}
  Dieser Algorithmus berechnet tatsächlich ein MIS.
\end{satz}

% §3.3. Minimum Makespan Scheduling

\begin{alg}[\Algorithm{Greedy Minimum Makespan Scheduling}] \mbox{}\\
  Gehe die Jobs in nach Dauer absteigender Reihenfolge durch, weise jeden Job dem Arbeiter zu, der bisher am wenigsten ausgelastet ist.
\end{alg}

\begin{satz}
  Die Lösung, die der Alg. liefert, ist höchstens um den Faktor
  \[ \nicefrac{4}{3} - \nicefrac{1}{3 p} \]
  schlechter als eine optimale Lösung.
\end{satz}

\begin{beweisskizze}
  Sei $t$ die Länge des letzten Jobs des am längsten beschäftigten Arbeiters und $z^*$ die minimale Gesamtdauer.
  \begin{itemize}
    \item Falls $t > \nicefrac{z^*}{3}$, so hat der Alg. sogar eine optimale Lsg gefunden.
    \item Falls $t \leq \nicefrac{z^*}{3}$, so folgt die Behauptung durch geeign. Abschätzen.
  \end{itemize}
\end{beweisskizze}

% §3.4. Maximum Knapsack

\begin{alg}[\Algorithm{Greedy Knapsack Packing}]
  Gehe die Sachen absteigend nach ihrem Nutzen-Kosten-Verhältnis~$\nicefrac{v_i}{w_i}$ durch und packe jede Sache ein, die noch in den Rucksack passt.
  Sei~$z$ der Gesamtnutzen des so zusammengestellten Sets.
  Falls eine Sache mit Nutzen $v_j > z$ (und $w_j \leq W$) nicht eingepackt wurde, so räume den Rucksack wieder aus und packe als einziges diese Sache ein.
\end{alg}

\begin{satz}
  Der Gesamtnutzen der durch den Algorithmus erhaltenen Lösung ist mindestens halb so groß wie der Gesamtnutzen einer optimalen Lösung.
\end{satz}

% §3.5. Minimum Set Cover

\begin{alg}[\Algorithm{Greedy Minimum Set Cover}]
  Beginne mit $\mathcal{C} \coloneqq \emptyset$, füge dann immer ein $T \in \mathcal{C}_0$ zu~$\mathcal{C}$ hinzu, welches
  \[ T \cap \left( {\bigcup}_{S \in \mathcal{C}_0} S \setminus {\bigcup}_{S \in \mathcal{C}} S \right) \]
  maximiert, bis ${\bigcup}_{S \in \mathcal{C}_0} S = {\bigcup}_{S \in \mathcal{C}} S$.
\end{alg}

% 3.5
\begin{satz}
  Sei $n \coloneqq {\max}_{S \in \mathcal{C}_0} \size{S}$.
  Die vom Greedy-Algorithmus berechnete Lösung ist maximal um den Faktor $H_n \coloneqq {\sum}_{j=1}^n \nicefrac{1}{j}$ schlechter als die optimale Lösung.
\end{satz}

\begin{samepage}

% §3.6. Minimum Vertex Coloring

\begin{bem}
  Es gibt keinen (einfachen) Greedy-Algorithmus, der das Minimum-Vertex-Coloring-Problem in guten Schranken löst.
\end{bem}

\section{Approximationsalgorithmen}

% 4.1
\begin{defn}
  Ein \emph{Approximationsalgorithmus} für ein Optimierungsproblem~$\OptTuple$ ist ein Algorithmus, der für jedes $x \in \Instances$ eine zulässige Lösung $y \in \Feasible(x)$ produziert.
\end{defn}

\end{samepage}

% §4.1 Absolute Approximation

% 4.2
\begin{defn}
  Sei $\OptTuple$ ein Optimierungsproblem und $x \in \Instances$ eine Instanz, für die $\Opt(x)$ existiert.
  Der \emph{absolute Fehler} von $y \in \Feasible(x)$ ist $\abs{Z(x, y) - \Opt(x)}$.
  % ausgelassen: zweiter Teil der Definition
\end{defn}

% 4.3
\begin{satz}[\Algorithm{Vizings Algorithmus}]
  Es gibt einen Algorithmus, der für jeden Graph $G = (V, E)$ eine Kantenfärbung mit höchstens $\Delta + 1$ Farben, wobei $\Delta \coloneqq {\max}_{v \in V} \deg_G(v)$, berechnet.
  % Beweisvideo: https://www.youtube.com/watch?v=otky1bBhwgM
\end{satz}

\begin{kor}
  Es gibt einen Polynomialzeit-Approximationsalg. für Minimum Edge Coloring mit Absolutfehler beschränkt durch~1.
\end{kor}

% §4.3. Relative Approximation

% 4.5
\begin{defn}
  Sei $\Prob = \OptTuple$ ein Optimierungsproblem mit $Z \geq 0$. \\
  Der \emph{relative Fehler} von $y \in \Feasible(x)$ zu~$x \in \Instances$ ist
  \[
    \begin{cases}
      0 & \text{falls } \Goal = \min, \ObjFun(x, y) = \Opt(x) = 0, \\
      (\ObjFun(x, y) - \Opt(x)) / \ObjFun(x, y) & \text{falls } \Goal = \min, Z(x, y) > 0, \\
      (\Opt(x) - \ObjFun(x, y)) / \Opt(x) & \text{falls } \Goal = \max.
    \end{cases}
  \]
\end{defn}

\begin{bem}
  Der relative Fehler ist eine Zahl in~$\cinterval{0}{1}$.
  Eine Lösung ist genau dann optimal, falls ihr relativer Fehler $= 0$ ist.
\end{bem}

% 4.5
\begin{defn}
  Ein \emph{$\epsilon$-Approximationsalgorithmus} ($\epsilon \in \cinterval{0}{1}$) für~$\Prob$ ist ein Algorithmus, der für jedes $x \in \Instances$ ein $y \in \Feasible(x)$ mit relativem Fehler $\leq \epsilon$ berechnet.
  Das Problem~$\Prob$ heißt \emph{$\epsilon$-approximierbar}, falls ein solcher Alg. mit polynomieller Laufzeit existiert.
\end{defn}

\begin{bspe}
  \begin{itemize}
    \item Minimum Makespan Scheduling ist $(1/4)$-approximierbar.
    \item Maximum Knapsack ist $(1/2)$-approximierbar.
    \item Minimum Set Cover ist $(\ln n / (1 + \ln n))$-approximierbar (bei Eingabegröße~$n$).
  \end{itemize}
\end{bspe}

% 4.6
\begin{defn}
  Sei $\Prob = \OptTuple$ ein Optimierungsproblem mit $Z \geq 0$. \\
  Das \emph{Approximationsverhältnis} von $y \in \Feasible(x)$ zu $x \in \Instances$ ist
  \[
    \begin{cases}
      1 & \text{falls } \ObjFun(x, y) = \Opt(x) = 0, \\
      \Opt(x) / \ObjFun(x, y) \in \cinterval{1}{\infty} & \text{falls } \Goal = \min, \Opt(x) > 0, \\
      \ObjFun(x, y) / \Opt(x) \in \cinterval{1}{\infty} & \text{falls } \Goal = \max, \ObjFun(x, y) > 0.
    \end{cases}
  \]
\end{defn}

\begin{bem}
  Das Approximationsverh. ist eine Zahl in~$\cinterval{1}{\infty}$.
  Eine Lösung ist genau dann optimal, falls ihr Approximationsverh. $= 1$ ist.
\end{bem}

\begin{defn}
  Ein Alg. heißt \emph{$r$-Approximationsalgorithmus} ($r \in \ocinterval{1}{\infty}$), falls er für jedes $x \in \Instances$ ein $y \in \Feasible(x)$ mit Approximationsverhältnis $\leq r$ liefert.
  Das Problem~$\Prob$ heißt \emph{$r$-approximierbar}, falls ein solcher Algorithmus mit polynomieller Laufzeit existiert.
\end{defn}

\begin{bem}
  Für das Approximationsverhältnis~$r$ und den relativen Fehler~$\epsilon$ von $y \in \Feasible(x)$ gilt
  \[
    r = 1 / (1-\epsilon), \qquad
    \epsilon = 1 - 1/\epsilon.
  \]
\end{bem}

% 4.7
\begin{defn}
  $\Defn{\APX}$ ist die Klasse aller Probleme in NPO, die $r$-Approximierbar für ein $r > 1$ sind.
\end{defn}

\begin{satz}
  Falls $\P \neq \NP$, so gilt Minimum TSP $\not\in \APX$.
\end{satz}

\begin{samepage}

\begin{beweisidee}
  Wäre Minimum TSP $r$-approximierbar, so könnte man diesen Algorithmus verwenden, um das NP-Problem, ob ein Graph einen Hamiltonweg besitzt, zu entscheiden.
\end{beweisidee}

% §4.3. The Traveling Salesman Problem
\subsection{Das Problem des Handelsreisenden}

\begin{erinnerung}
  Minimale Spannbäume für einen gewichteten ungerichteten Graphen können in polynomieller Zeit mit Kruskals oder mit Prims Algorithmus berechnet werden.
\end{erinnerung}

\end{samepage}

\begin{satz}
  Minimum $\Delta$-TSP ist 2-approximierbar.
\end{satz}

\begin{beweisskizze}
  Sei $(V, c)$ eine Instanz und $z^*$ die minimale Länge einer Tour.
  Berechne einen minimalen Spannbaum.
  Dessen Kanten haben eine Gesamtlänge von $\leq z^*$.
  Führe Tiefensuche im Spannbaum durch und liste jeden neu entdeckten Knoten auf.
  Die so erhaltene Tour hat (wegen der Dreiecksungleichung) Länge $\leq 2 z^*$.
\end{beweisskizze}

\begin{defn}
  Ein ungerichteter Multigraph heißt \em{Eulersch}, falls er eine \textit{Eulertour} besitzt, also eine Tour, die jede Kante nur ein Mal benutzt.
\end{defn}

% 2.12
\begin{lem}
  Ein zshgder ungerichteter Multigraph ist genau dann Eulersch, wenn alle seine Knoten den Grad zwei haben.
  In dem Fall kann man eine Eulertour in Polynomialzeit finden.
\end{lem}

\begin{lem}
  Sei $(V, c)$ eine Instanz des Minimum $\Delta$-TSP.
  Aus jedem Eulerschen Multigraph auf der Knotenmenge~$V$ mit Gesamtkantengewicht $C$ kann man eine TSP-Tour der Gesamtlänge~$\leq C$ in Polynomialzeit berechnen.
\end{lem}

% 4.13
\begin{defn}
  Sei $G = (V, E)$ ein unger. Graph.
  Ein \emph{Matching} in~$G$ ist eine Teilmenge $E' \subseteq E$, sodass $e \cap e' = \emptyset$ für alle $e, e' \in E'$ mit $e \neq e'$.
  Ein Matching heißt \emph{perfekt}, falls $V = \cup_{e \in E'} e$.
  Die \textit{Kosten} eines Matchings bzgl. einer Kostenfunktion $c : E \to \R_{\geq 0}$ sind ${\sum}_{e \in E'} c(e)$.
\end{defn}

% 4.14
\begin{satz}
  Ein perfektes Matching maximaler Größe mit minimalen Kosten (unter den Matchings maximaler Größe) kann für einen Graphen $G$ mit $n$ Knoten in Zeit $n^{o(1)}$ berechnet werden.
\end{satz}

% 4.15
\begin{satz}[\emph{Christofides}]
  Minimum $\Delta$-TSP ist $3/2$-approximierbar.
\end{satz}

\begin{beweisskizze}
  Sei $(V, c)$ eine Instanz und $z^*$ die minimale Länge einer Tour.
  Berechne einen minimalen Spannbaum.
  Berechne ein perfektes Matching mit minimalen Kosten auf den Knoten des Stammbaums mit ungeradem Grad.
  Die Kosten dieses Matchings sind $\leq z^* / 2$.
  Durch Hinzufügen der Kanten des Matchings zum Spannbaum erhalten wir einen Eulerschen Multigraphen mit Gesamtkosten $\leq 3/2 z^*$.
  Aus diesem erhalten wir eine Tour der Länge $\leq 3/2 z^*$.
\end{beweisskizze}

\subsection{Nochmal Minimum Vertex Coloring}

\begin{alg}[\Algorithm{Greedy Vertex Coloring}] \mbox{}\\
  Wiederhole folgende Schritte, bis alle Knoten gefärbt sind:
  \begin{enumerate}
    \item
      Bestimme ein nicht-vergrößerbares IS~$I$ in~$G$ wie folgt: Setze $H \coloneqq G$, $I \coloneqq \emptyset$, dann führe folgende Schritte aus, solange $H \neq \emptyset$:
      \begin{enumerate}
        \item Wähle einen Knoten~$v$ minimalen Grades aus~$H$ aus.
        \item Füge $v$ zu~$I$ hinzu.
        \item Lösche $v$ und seine Nachbarknoten aus~$H$.
      \end{enumerate}
    \item Färbe alle Knoten in~$I$ in einer noch unbenutzten Farbe.
    \item Lösche die Knoten in~$I$ aus~$G$.
  \end{enumerate}
\end{alg}

\begin{satz}
  Greedy Vertex Coloring ist (für Graphen mit $n$~Knoten) ein $\O(n / \log n)$-Approximationsalgorithmus.
\end{satz}

% §5. Tree-Search Strategies
\section{Baumsuche}

% §5.1. Erschöpfende Suche

% §5.2. Branch and Bound

\begin{strategie}[\emph{Branch and Bound} für Minimierungsprobleme]
  Organisiere den Suchraum als Baum, der zunächst nur eine Wurzel enthält, wobei mögliche Lösungen aus~$\Feasible(x)$ Blätter sind und "`partielle Lösungen"' (die zu einer möglichen Lösung erweitert werden können oder auch nicht) die Verzweigungen bilden.
  Es ist nicht praktikabel, den gesamten Baum zu durchsuchen.
  Darum mache folgendes:
  Beschrifte die Verzweigungen mit einer (kostengünstig) berechneten unteren Schranke für die Kosten einer Lösung, die Erweiterung der partiellen Lösung ist.
  Expandiere dann wiederholt eine Verzweigung im Baum, \dh{} berechne seine Kindknoten und beschrifte sie mit einer unteren Schranke der Kosten.
  Verzweigungen, deren untere Schranke mindestens so groß ist wie die Kosten einer bisher gefundenen möglichen Lösung müssen nicht expandiert werden.
  Gibt es keine Verzweigung mehr, die expandiert werden muss, so ist die bisher gefundene mögliche Lösung mit minimalen Kosten eine optimale Lösung.
\end{strategie}

\begin{bem}
  Der Algorithmus kann auch früher abgebrochen werden, etwa wenn die unteren Schranken nur etwas kleiner sind als die Kosten der besten bisher gefundenen Lösung und wenn man mit einer approximativen Lösung zufrieden ist.
\end{bem}

\begin{bsp}
  Für das TSP auf $(V, E)$ sind partielle Lösungen Pfade $p = u_0 \cdots u_m$ beginnend bei einem Startknoten~$u_0$.
  Eine untere Kostenschranke für Touren, die Erweiterung des Pfades~$p$ sind, ist
  \[
    \arraycolsep=1pt
    d \coloneqq
    \begin{array}[t]{r l}
      & \min \Set{c(u_0, v)}{v \in V \setminus \{ u_0, \cdots, u_k \}} \\
      +& \min \Set{c(u_k, v)}{v \in V \setminus \{ u_0, \cdots, u_k \}} \\
      +& \text{Summe der Kosten der $n-k-1$ kostengünstigsten} \\
      & \text{Kanten zwischen Knoten in } \{ u_0, \cdots, u_k \}
    \end{array}
  \]
\end{bsp}

\begin{bem}
  In der Praxis schaffen Branch-and-Bound-Algorithmen (für NP-schwere Probleme) oft eine drastische Verkleinerung des Suchraums.
  Theoretisch haben sie jedoch für gewöhnlich exponentielle Laufzeit.
\end{bem}

% §5.3. 3-Satisfiability

\begin{nota}
  Für eine logische Formel $F$ und eine Variable $x$ sei $F|_{x=i}$ ($i \in \{0,1\}$) die Formel, die man erhält, wenn man $x$ durch $i$ in~$F$ ersetzt und vereinfacht.
\end{nota}

\begin{satz}
  Eine Instanz $F$ von 3-SAT kann in Zeit $\O(\abs{F} \cdot \alpha_0^n)$ entschieden werden, wobei $\alpha_0 \approx 1.84$ und $\abs{F}$ die Gesamtzahl der Literale in~$F$ ist.
\end{satz}

\begin{algorithmic}
  \Function{Decide}{$F$}
    \If{\text{$F$ hat keine Clauses}}
      \Return true
    \EndIf
    \State wähle eine Clause $l_1 \vee \cdots \vee l_k$ in $F$ (mit $k \in \{ 0, 1, 2, 3 \}$)
    \For{$i := 1, \ldots, k$}
      \If{\Call{Decide}{$F|_{l_1=0,\ldots,l_{i-1}=0,l_i=1}$}}
        \Return true
      \EndIf
    \EndFor
    \State \Return false
  \EndFunction
\end{algorithmic}

% §5.4. Minimum Vertex Cover

% 5.2
\begin{satz}
  Instanzen von Minimum Vertex Cover mit $n$~Knoten und $m$~Kanten können in Zeit $\O(3^{n/2} \cdot m + n)$ gelöst werden.
\end{satz}

\begin{nota}
  Für einen Graphen $G = (V, E)$ und Knoten $W \subseteq V$ sei $G - W$ der Graph $(V', \Set{\{u, w\} \in E}{u, w \in V'})$ mit $V' \coloneqq V \setminus W$, der durch Löschen von~$W$ entsteht.
\end{nota}

\begin{algorithmic}
  \Function{ComputeMVC}{$G = (V, E)$}
    \If{$G = \emptyset$} \Return $\emptyset$ \EndIf
    \If{$G$ hat isolierten Knoten $u$}
      \State \Return $\Call{ComputeMVC}{G - \{ u \}}$
    \EndIf
    \If{$G$ hat Knoten $u$ vom Grad~1}
      \State sei $v$ der Knoten mit $\{ u, v \} \in E$
      \State \Return $\{ v \} \cup \Call{ComputeMVC}{G - \{ u, v \}}$
    \EndIf
    \If{$G$ hat Dreieck mit Eckknoten $u$, $v$, $w$}
      \State $C_{u,v} \coloneqq \{u, v\} \cup \Call{ComputeMVC}{G - \{ u, v \}}$
      \State $C_{u,w} \coloneqq \{u, w\} \cup \Call{ComputeMVC}{G - \{ u, w \}}$
      \State $C_{v,w} \coloneqq \{v, w\} \cup \Call{ComputeMVC}{G - \{ v, w \}}$
      \State \Return kleinste der Überdeckungen $C_{u,v}$, $C_{u,w}$ und $C_{v,w}$
    \EndIf
    \If{$G$ hat einfachen Pfad mit Knoten $u, v, w$ und $z$}
      \State $C_{u,w} \coloneqq \{u, w\} \cup \Call{ComputeMVC}{G - \{ u, w \}}$
      \State $C_{v,w} \coloneqq \{v, w\} \cup \Call{ComputeMVC}{G - \{ v, w \}}$
      \State $C_{v,z} \coloneqq \{v, z\} \cup \Call{ComputeMVC}{G - \{ v, z \}}$
      \State \Return kleinste der Überdeckungen $C_{u,w}$, $C_{v,w}$ und $C_{v,z}$
    \EndIf
  \EndFunction
\end{algorithmic}

\begin{bem}
  In der Umgebung jedes Knoten eines Graphen tritt einer der vier Fälle auf.
  Es kann daher in konstanter Zeit einer der vier Fälle ausgewählt werden.
  (Es muss nicht darauf geachtet werden, die Fälle von oben nach unten durchzuarbeiten!)
\end{bem}

Wir sagen, ein Fall \textit{verzweigt gemäß} $A_1, \ldots, A_k$, falls er den Algorithmus rekursiv mit Argumenten $G - A_1$, \ldots, $G - A_k$ aufruft.
Die Multimenge $\{ \size{A_1}, \ldots, \size{A_k} \}$ heißt zugehörige \textit{Verzweigungs- multimenge}.
Für eine solche Multimenge $\{ a_1, \ldots, a_k \}$ setzen wir
\[ \alpha(a_1, \ldots, a_k) \coloneqq \max \, \Set{x \geq 1}{x^{-a_1} + \ldots + x^{-a_k} \geq 1}. \]
Schaffen wir es, einen Algorithmus mit $m$~Fällen mit Verzweigungs- multimengen $A_1, \ldots, A_m$ anzugeben (sodass in konstanter Zeit entschieden werden kann, welcher Fall vorliegt), so läuft der Algorithmus in Zeit $\O(\alpha_0^n \cdot m + n)$, wobei $\max \, \Set{\alpha(A_i)}{i = 1, \ldots, m}$

% 5.3
\begin{satz}
  Instanzen von Minimum Vertex Cover mit $n$~Knoten und $m$~Kanten können in Zeit $\O(\alpha_0^n \cdot m + n)$ gelöst werden, wobei $\alpha_0 \approx 1,325$ die Wurzel von $x^3 - x - 1$ ist.
\end{satz}

% §6. Dynamic Programming
\section{Dynamische Programmierung}

% §6.1. Maximum Integer Knapsack

% 6.1
\begin{satz}
  Sei $P = (v_1, \ldots, v_n, w_1, \ldots, w_n)$ eine Instanz von Maximum Integer Knapsack.
  Setze $V \coloneqq v_1 + \ldots + v_n$.
  Dann kann $P$ in Zeit $\O(n V)$ gelöst werden.
\end{satz}

\begin{alg}[\Algorithm{Knapsack mit dynam. Programmierung}] \mbox{}\\
  Löse mit dyn. Progr. die Unterprobleme $(P_{j,v})_{1 \leq j \leq n, 1 \leq v \leq V}$ mit
  \[
    P_{j,v} \coloneqq
      \begin{array}[t]{l}
        \text{finde $S \subset \{ 1, \ldots, j \}$ mit ${\sum}_{i \in S} v_i = v$ und} \\
        \text{${\sum}_{i \in S} w_i$ minimal unter allen solchen Teilmengen!}
      \end{array}
  \]
  Die Lösung ergibt sich aus den Lösungen von $P_{n,1}, \ldots, P_{n,V}$.
\end{alg}

\begin{bem}
  Die Laufzeit ist \emph{pseudopolynomiell}: Sie hängt polynomiell von den in der Eingabe enthaltenen Zahlen ab.
\end{bem}

% §6.2 Minimum Bin Packing

% 6.2
\begin{satz}
  Instanzen~$P$ von Minimum Bin Packing mit $n$~Objekten in $r$~versch. Größen können in Zeit~$\O(n^{2r+2})$ gelöst werden.
\end{satz}

\begin{alg}
  Seien $s_1, \ldots, s_r$ die verschiedenen Größen. \\
  Wir nennen einen Vektor $A = (a_1, \ldots, a_r) \in \N^r$ einen \textit{Packungstyp}, falls ${\sum}_{i=1}^r a_i s_i \leq 1$.
  Sei $\{ A_1, \ldots, A_t \}$ die Menge aller Packungstypen.
  Löse mit dyn. Programmierung die Unterprobleme
  \[
    P_{j,B} \coloneqq
      \begin{array}[t]{l}
        \text{finde $f : \{ 1, \ldots, j \} \to \N$ mit ${\sum}_{i=1}^j f(i) \cdot A_i = B$ und} \\
        \text{${\sum}_{i=1}^j f(i)$ ist minimal unter all solchen $f$.}
      \end{array}
  \]
  mit $1 \leq j \leq t$ und $B \in \{ 1, \ldots, n \}^r$ mit $B \leq P$.
  Das ursprüngliche Problem ist $P_{t,P}$.
\end{alg}

\section{Polynomialzeit-Approximationsschemata}

% 7.2
\begin{defn}
  Ein \emph{Polynomialzeit-Approximationsschema} (PTAS) für $\Prob \in \NPO$ ist ein Algorithmus, der für jede Instanz~$x$ von~$\Prob$ und $\epsilon > 0$ eine mögliche Lösung in~$\Feasible(x)$ mit relativem Fehler $\leq \epsilon$ liefert und dessen Laufzeit für jedes fixe $\epsilon > 0$ polynomiell in~$\size{x}$ ist.
\end{defn}

\begin{defn}
  $\Defn{\PTAS} \coloneqq \Set{\Prob \in \NPO}{\text{$\Prob$ hat ein PTAS}}$
\end{defn}

\begin{bem}
  $\PO \subseteq \PTAS \subseteq \APX$
\end{bem}

% 7.1
\begin{satz}
  Es gibt einen Algorithmus, der für jedes $\epsilon > 0$ und jede Instanz $(v_1, \ldots, v_n, w_1, \ldots, w_n, W)$ von Maximum Knapsack in Zeit $\O(n^3 / \epsilon)$ eine $\epsilon$-approximative Lösung liefert.
\end{satz}

\begin{alg}
  \begin{enumerate}
    \item Setze $K \coloneqq \epsilon V / n^2$, wobei $V \coloneqq v_1 + \ldots + v_n$.
    \item Löse die Instanz $(\floor{v_1/K}, \ldots, \floor{v_n/K}, w_1, \ldots, w_n, W)$ von Maximum \textit{Integer} Knapsack mit dem Algorithmus basierend auf dynamischer Programmierung.
    \item Die Lösung dieses geänderten Problems ist eine $\epsilon$-Approximation des ursprünglichen Problems.
  \end{enumerate}
\end{alg}

% 7.3
\begin{lem}
  Es gibt einen Algorithmus, der für jede Instanz von \textit{Minimum Bin Packing} mit $n$~Objekten der Größe~$\geq \delta$ eine Packung der Objekte in $(1 + \delta) z^* + 1$ Behälter in Zeit $\O(n^{2/\delta^2 + 2})$ berechnet, wobei $z^*$ die optimale Zahl der Behälter ist.
\end{lem}

% 7.4
\begin{satz}
  Es gibt einen Algorithmus, der für jede Instanz von \textit{Minimum Bin Packing} mit $n$~Objekten eine Packung der Objekte in $(1 + \delta) z^* + 1$ Behälter in Zeit $\O(n^{8/\delta^2 + 2})$ berechnet.
\end{satz}

% 7.5
\begin{defn}
  Ein \emph{asymptot. Polynomialzeit-Approximationsschema} (APTAS) für $\OptTuple{}$ ist ein Algorithmus, der für alle $x \in \Instances{}$ und $\epsilon > 0$ eine mögliche Lösung $y \in \Feasible(x)$ mit
  \[ \abs{Z(x, y) - \Opt(x)} \leq \epsilon \cdot \max \{ Z(x,y), \Opt(x) \} + K \]
  für eine Konstante~$K$ berechnet und dessen Laufzeit für alle festen~$\epsilon$ polynomiell in $\size{x}$ ist.
\end{defn}

\begin{defn}
  Ein (asympt.) \emph{Voll-Polynomialzeit-Approx'schema} ((A)FPTAS) für $\Prob{}$ ist ein (A)PTAS für~$\Prob{}$, dessen Laufzeit für die Instanz $(x, \epsilon)$ durch ein Polynom in $\size{x}$ und in~$1/\epsilon$ beschränkt ist.
\end{defn}

\begin{defn}
  $\Defn{\mathrm{(A)(F)PTAS}} \coloneqq \Set{\Prob \in \NPO}{\text{$\Prob$ hat ein (A)(F)PTAS}}$
\end{defn}

\begin{bspe}
  \begin{itemize}
    \item Maximum Knapsack $\in \FPTAS$
    \item Wir haben gezeigt: Minimum Bin Packing $\in \APTAS$
    \item Man kann zeigen: Minimum Bin Packing $\in \AFPTAS$
  \end{itemize}
\end{bspe}

% §8. Parametrization
\section{Parametrisierung}

\begin{vorgehen}
  Füge einen weiteren Parameter (zusätzlich zu den Größenparametern) für Probleminstanzen ein, suche nach einem Algorithmus, dessen Laufzeit wesentlich von diesem Parameter abhängt, sodass Instanzen, die einen kleinen Wert für den Parameter haben, in akzeptabler Zeit gelöst werden können.
\end{vorgehen}

% §8.1. Minimum Vertex Cover

% 8.1
\begin{satz}
  Es gibt einen Algorithmus, der gegeben einen Graphen~$G$ mit $n$~Ecken und $m$~Kanten und ein $k \geq 0$ in Zeit $\O(n \cdot 1,325^{k} + m)$ ein Minimum Vertex Cover der Größe $\leq k$ berechnet, falls ein solches existiert (falls nicht, so soll der Algorithmus "`keine Lösung"' zurückgeben).
\end{satz}

\begin{idee}
  Verwende den rekursiven Baumsuche-Algorithmus für Minimum-Vertex-Cover, aber breche die Rekursion ab, wenn das sich in Konstruktion befindende Cover Größe $> k$ erreicht.
  Außerdem optimiere rekursive Aufrufe dadurch, dass der Graph nicht kopiert für den Aufruf kopiert wird.
\end{idee}

% 8.3
\begin{satz}
  Es gibt einen Algorithmus, der gegeben einen Graphen~$G$ mit $n$~Ecken und $m$~Kanten und ein $k \geq 0$ in Zeit $\O(k^2 \cdot 1,325^{k} + n + m)$ ein Minimum Vertex Cover der Größe $\leq k$ berechnet, falls ein solches existiert.
\end{satz}

\begin{idee}
  Füge jeden Knoten mit Grad $\geq k$ zum Cover hinzu (da jedes Cover der Größe $\leq k$ diese enthalten muss).
  Wir können somit annehmen, dass der Maximalgrad in~$G$ $\leq k$ ist.
  Lösche alle isolierten Knoten aus~$G$.
  Es gilt: Falls $G$ nun mehr als $k^2$ Kanten oder mehr als $k^2 + k$ Ecken hat, so besitzt $G$ kein Vertex Cover der Größe $\leq k$ und wir können "`keine Lösung"' ausgeben.
  Ansonsten verwende den Algorithmus vom letzten Satz.
\end{idee}

\begin{bem}
  Wir haben damit die Probleminstanz auf einen kleineren \text{Kern} reduziert.
  Diese Technik heißt \textit{kernelization}.
\end{bem}

% §8.2. MaxSAT

% ausgelassen: Lemma 8.4 und 8.5

% 8.7
\begin{lem}
  Für eine Formel~$F$ in konj. NF, in der jede Variable, die in positiver wie negativer Form vorkommt, genau zwei mal vorkommt, kann in Zeit $\O(\size{F})$ eine Zuweisung von Variablen gefunden werden, die die Anzahl der erfüllten Clauses maximiert.
\end{lem}

% 8.8
\begin{satz}
  Es gibt einen Algorithmus, der gegeben einer Formel in konj. NF und $k \in \N$ in Zeit $\O(k^2 \phi^k + \size{F})$, wobei $\phi = (1 + \sqrt{5}) / 2$, eine Zuweisung der Variablen in~$F$ berechnet, sodass $k$ Clauses erfüllt sind, oder entscheidet, dass es keine solche Zuweisung gibt.
\end{satz}

Folgender Algorithmus entscheidet bloß, ob es eine solche Zuweisung gibt, man kann ihn aber so abändern, dass er auch eine Zuweisung berechnet:

\begin{algorithmic}
  \Function{DecideMaxSAT}{$F$, $k$}
    \State entferne überflüssige Literale aus allen Clauses
    \State $m \coloneqq $ Anzahl von Clauses in~$F$
    \If{$m < k$} \Return false \EndIf
    \If{$k \leq \floor{m/2}$} \Return true \EndIf
    \State $F_L \coloneqq $ Konjunktion der \textit{long Clauses} in~$F$ mit $\geq k$ Literalen
    \State $F_S \coloneqq $ Konjunktion der \textit{short Clauses} in~$F$ mit $< k$ Literalen
    \State $m_L \coloneqq $ Anzahl Clauses in $F_L$
    \Return $\Call{Search}{F_S, k - m_L}$
  \EndFunction

  \Function{Search}{$F'$, $j$}
    \If{$j \leq 0$} \Return true \EndIf
    \If{$F'$ hat weniger als $j$ Clauses} \Return false \EndIf
    \If{keine Variable tritt positiv und negativ in $F'$ auf}
      \State \Return true
    \EndIf
    \State Wähle unter den Variablen mit positiv und negativ auftreten,
    \State \quad eine Variable $x$, die am öftesten auftritt
    \State $m_0 \coloneqq $ Anzahl der negativen Vorkommen von~$x$
    \State $m_1 \coloneqq $ Anzahl der positiven Vorkommen von~$x$
    \If{$m_0 = m_1 = 0$}
      \State $k' \coloneqq $ max. Anzahl von erfüllb. Clauses in $F'$ (siehe Lem.)
      \State \Return $k' \geq j$
    \Else
      \If{$\Call{Search}{F'|_{x=0}, j - m_0}$}
        \Return true
      \EndIf
      \Return $\Call{Seach}{F'|_{x=1}, j - m_1}$
    \EndIf
  \EndFunction
\end{algorithmic}

Mit einer etwas einfacheren $\Call{Search}{}$-Prozedur kann man schon zeigen:

% 8.6
\begin{satz}
  Es gibt einen Algorithmus, der gegeben einer Formel in konj. NF und $k \in \N$ in Zeit $\O(k^2 2^k + \size{F})$ eine Zuweisung der Variablen in~$F$ berechnet, sodass $k$ Clauses erfüllt sind, oder entscheidet, dass es keine solche Zuweisung gibt.
\end{satz}

\section{Probleme}

\begin{problem}[\Problem{Maximum Independent Set}, MIS]
  Geg. einen unger. Graphen~$(V, E)$, berechne eine \textit{unabh. Menge}~$M \subseteq V$, \dh{}
  \[
    \fa{v \in M} \fa{w \in V} (v, w) \in E \implies w \not\in M,
  \]
  die maximale Größe~$\size{M}$ unter allen unabhängigen Mengen besitzt.
\end{problem}

\begin{problem}[\Problem{Minimum Vertex Cover}, MVC]
  Geg. einen unger. Graphen~$G = (V, E)$, berechne eine \textit{Knotenüberdeckung}~$C$, \dh{}
  \[
    \fa{v, w \in V} \{v, w\} \in E \implies v \in C \vee w \in C,
  \]
  die minimale Größe~$\size{C}$ unter allen Knotenüberdeckungen besitzt.
\end{problem}

\begin{bem}
  Für einen Graphen $(V, E)$ und eine Teilmenge $S \subseteq V$ gilt: \\
  $S$ ist eine unabhängige Menge $\iff$ $V \setminus S$ ist ein Vertex Cover \\
  Die Probleme MIS und MVC sind damit äquivalent.
\end{bem}

\begin{defn}
  Ein \emph{Intervallmodell} eines Graphen $G = (V, E)$ ist eine Abbildung $\phi : E \to \Set{\cinterval{a}{b}}{a, b \in \Q}$, sodass
  \[
    \fa{v \neq w \in V} \enspace
    (v, w) \in E \iff \phi(v) \cap \phi(w) \neq \emptyset.
  \]
  Ein Graph heißt \emph{Intervallgraph}, falls er ein Intervallmodell besitzt.
\end{defn}

\begin{problem}[\Problem{Minimum Makespan Scheduling}]
  Seien $p, n \in \N$ und $l_1, \ldots, l_n \in \R_{> 0}$ gegeben.
  Für $f : \{ 1, \ldots, n \} \to \{ 1, \ldots, p \}$ setze
  \[ t(f) \coloneqq \max_{1 \leq i \leq p} \sum_{j \in f^{-1}(i)} l_j. \]
  Berechne das~$f$, für das $t(f)$ minimal wird!
\end{problem}

\begin{interp}
  $p$ ist die Anzahl von \textit{Arbeitern},
  $l_1, \ldots, l_n$ sind die Längen von zu erledigenden \textit{Jobs}
  und $t(f)$ ist die \textit{Gesamtdauer} bei der durch~$f$ gegebenen Verteilung der Jobs auf die Arbeiter an.
\end{interp}

\begin{bem}
  MMS ist NP-hart, da das zugeh. Entscheidungsproblem Bin Packing bekannterweise NP-hart ist.
\end{bem}

\begin{problem}[\Problem{Maximum Knapsack}]
  Seien $n \in \N$ und $v_1, \ldots, v_n$, $w_1, \ldots, w_n, W \in \R_{> 0}$ gegeben.
  Die Menge der möglichen Lsgn sei
  \[ \Feasible \coloneqq \Set{S \subseteq \{ 1, \ldots, n \}}{{\sum}_{i \in S} w_i \leq W}. \]
  Gesucht: ${\argmax}_{S \in \Feasible} {\sum}_{i \in S} v_i$
\end{problem}

\begin{interp}
  Man wählt unter $n$ Sachen mit jeweils einem \textit{Gewicht}~$w_i$ und einem \textit{Nutzwert}~$v_i$ diejenigen aus, die man in einen Rucksack packt, sodass das Gesamtgewicht eine festgelegte Grenze~$W$ nicht übersteigt und der Nutzen maximal wird.
\end{interp}

\begin{problem}[\Problem{Maximum Integer Knapsack}] \mbox{}\\
  Wie Maximum Knapsack aber mit $v_1, \ldots, v_n \in \N_{> 0}$.
\end{problem}

\begin{problem}[\Problem{Minimum Set Cover}]
  Gegeben seien $n \in \N$ und $\mathcal{C}_0 \subseteq \Powerset(\{ 1, \ldots, n \})$.
  Die Menge der möglichen Lösungen ist
  \[ \Feasible \coloneqq \Set{\mathcal{C} \subseteq \mathcal{C}_0}{{\bigcup}_{S \in \mathcal{C}} S = {\bigcup}_{S \in \mathcal{C}_0} S} \]
  Aufgabe: Finde $\mathcal{C} \in \Feasible$ mit minimalem $\size{\mathcal{C}}$!
\end{problem}

\begin{bem}
  Minimum Set Cover verallgemeinert Minimum Vertex Cover.
\end{bem}

\begin{problem}[\Problem{Minimum Vertex Coloring}]
  Gegeben sei ein unger. Graph~$G = (V, E)$.
  Die Menge der \textit{Eckenfärbungen} ist
  \[
    \Feasible \coloneqq \Set{\text{Abbildungen } c : V \to \N}{\fa{\{v, w\} \in E} c(v) \neq c(w)}.
  \]
  Ziel: Finde $c \in \Feasible$ mit minimaler Anzahl $\max c(V)$ an Farben.
\end{problem}

\begin{problem}[\Problem{Minimum Edge Coloring}]
  Gegeben sei ein unger. Graph~$G = (V, E)$.
  Die Menge der \textit{Kantenfärbungen} ist
  \[
    \Feasible \coloneqq \Set{\text{Abb. } c : E \to \N}{\fa{e_1 \neq e_2 \in E} e_1 \cap e_2 \neq \emptyset \implies c(e_1) \neq c(e_2)}
  \]
  Ziel: Finde $c \in \Feasible$ mit minimaler Anzahl $\max c(V)$ an Farben.
\end{problem}

\begin{problem}[\Problem{Minimum TSP}]
  Gegeben sei ein vollständiger unger. Graph $G = (V, E)$ und eine Abb. $c : E \to \R_{\geq 0}$.
  % Gegeben sei eine endliche Menge $V$ und eine Abb. $c : V \times V \to \R_{\geq 0}$ mit $c(x, y) = c(y, x)$ für alle $x, y \in V$.
  Gesucht ist eine zyklische Permutation $\sigma$ von~$V$ (eine \textit{Tour}), sodass die \textit{Länge} ${\sum}_{v \in V} c(\{ v, \sigma(v) \})$ minimal wird.
\end{problem}

\begin{problem}[\Problem{Minimum $\Delta$-TSP}]
  Gegeben sei ein endlicher metrischer Raum~$(V, c)$.
  Gesucht ist eine zyklische Permutation $\sigma$ von~$V$ (eine \textit{Tour}), sodass die \textit{Länge} ${\sum}_{v \in V} c(v, \sigma(v))$ minimal wird.
\end{problem}

\begin{problem}[\Problem{$k$-SAT(isfiability)}]
  Gegeben sei eine Formel in konjunktiver Normalform, etwa
  \[ (x_1 \vee x_2 \vee \overline{x_3}) \wedge (\overline{x_1} \vee \overline{x_3} \vee x_4 \vee \overline{x_5}) \wedge (x_2 \vee x_5) \wedge (x_3 \vee \overline{x_4}). \]
  Die Maximalzahl an \textit{Literalen} in einer \textit{Clause} sei dabei $\leq k$.
  Entscheide, ob die Formel \emph{erfüllbar} ist,\dh{} ob es eine Zuweisung der Variablen gibt, sodass die Formel wahr ist.
\end{problem}

\begin{problem}[\Problem{MaxSAT}]
  Gegeben eine Formel in konjunktiver Normalform, finde eine Zuweisung der Variablen, die die Anzahl der gültigen Clauses maximiert.
\end{problem}

\begin{problem}[\Problem{Minimum Bin Packing}]
  Gegeben seien \textit{Objektgrößen} $v_1, \ldots, v_n \in \cinterval{0}{1}$.
  \textit{Packungen} sind Abbildungen $f : \{ 1, \ldots, n \} \to \N$, die jedem \textit{Objekt} einen \textit{Behälter} (mit Volumen 1) zuweisen, sodass
  \[
    {\sum}_{i \in f^{-1}(j)} v_i \leq 1 \quad
    \text{für alle $j \in \N$.}
  \]
  Gesucht ist ein~$f$ mit minimaler Anzahl $\max \im(f)$ von Behältern.
\end{problem}

\end{document}
